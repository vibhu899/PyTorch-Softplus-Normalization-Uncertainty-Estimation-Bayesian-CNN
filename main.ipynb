{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'alexnet'\n",
    "dataset = 'CIFAR10'\n",
    "outputs = 10\n",
    "inputs = 3\n",
    "resume = False\n",
    "n_epochs = 150\n",
    "lr = 0.01\n",
    "weight_decay = 0.0005\n",
    "num_samples = 1\n",
    "beta_type = \"Blundell\"\n",
    "resize=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 256\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    # Uncomment if normalizing the data\n",
    "    #img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = np.squeeze(images[3])\n",
    "channels = ['red channel', 'green channel', 'blue channel']\n",
    "\n",
    "fig = plt.figure(figsize = (36, 36)) \n",
    "for idx in np.arange(rgb_img.shape[0]):\n",
    "    ax = fig.add_subplot(1, 3, idx + 1)\n",
    "    img = rgb_img[idx]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(channels[idx])\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', size=8,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBConv2d(nn.Module):\n",
    "    def __init__(self, q_logvar_init, p_logvar_init, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(BBBConv2d, self).__init__()\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        self.q_logvar_init = q_logvar_init\n",
    "        self.p_logvar_init = p_logvar_init\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.bias = bias\n",
    "\n",
    "        self.mu_weight = Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n",
    "        self.sigma_weight = Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n",
    "        self.register_buffer('eps_weight', torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels\n",
    "        n *= self.kernel_size ** 2\n",
    "        stdv = 1.0 / math.sqrt(n)\n",
    "        self.mu_weight.data.uniform_(-stdv, stdv)\n",
    "        self.sigma_weight.data.fill_(self.p_logvar_init)\n",
    "\n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def convprobforward(self, input):\n",
    "        sig_weight = torch.exp(self.sigma_weight)\n",
    "        weight = self.mu_weight + sig_weight * self.eps_weight.normal_()\n",
    "        kl_ = math.log(self.q_logvar_init) - self.sigma_weight + (sig_weight**2 + self.mu_weight**2) / (2 * self.q_logvar_init ** 2) - 0.5\n",
    "        bias = None\n",
    "        \n",
    "        out = F.conv2d(input, weight, bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        kl = kl_.sum() \n",
    "        return out, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBLinearFactorial(nn.Module):\n",
    "    def __init__(self, q_logvar_init, p_logvar_init, in_features, out_features, bias=False):\n",
    "        super(BBBLinearFactorial, self).__init__()\n",
    "        self.q_logvar_init = q_logvar_init\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.p_logvar_init = p_logvar_init\n",
    "        self.mu_weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.sigma_weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.register_buffer('eps_weight', torch.Tensor(out_features, in_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.mu_weight.size(1))\n",
    "        self.mu_weight.data.uniform_(-stdv, stdv)\n",
    "        self.sigma_weight.data.fill_(self.p_logvar_init)\n",
    "        self.eps_weight.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "\n",
    "    def fcprobforward(self, input):\n",
    "        sig_weight = torch.exp(self.sigma_weight)\n",
    "        weight = self.mu_weight + sig_weight * self.eps_weight.normal_()\n",
    "        kl_ = math.log(self.q_logvar_init) - self.sigma_weight + (sig_weight**2 + self.mu_weight**2) / (2 * self.q_logvar_init ** 2) - 0.5\n",
    "        bias = None\n",
    "        out = F.linear(input, weight, bias)\n",
    "        kl = kl_.sum() \n",
    "        return out, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBAlexNet(nn.Module):\n",
    "    '''The architecture of AlexNet with Bayesian Layers'''\n",
    "\n",
    "    def __init__(self, outputs, inputs):\n",
    "        super(BBBAlexNet, self).__init__()\n",
    "\n",
    "        self.q_logvar_init = 0.05\n",
    "        self.p_logvar_init = math.log(0.05)\n",
    " \n",
    "        self.classifier = BBBLinearFactorial(self.q_logvar_init, self.p_logvar_init, 1* 1 * 128, outputs)\n",
    "\n",
    "        self.conv1 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, inputs, 64, kernel_size=11, stride=4, padding=5)\n",
    "        self.soft1 = nn.Softplus()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = BBBConv2d(self.q_logvar_init,  self.p_logvar_init, 64, 192, kernel_size=5, padding=2)\n",
    "        self.soft2 = nn.Softplus()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, 192, 384, kernel_size=3, padding=1)\n",
    "        self.soft3 = nn.Softplus()\n",
    "\n",
    "        self.conv4 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, 384, 256, kernel_size=3, padding=1)\n",
    "        self.soft4 = nn.Softplus()\n",
    "\n",
    "        self.conv5 = BBBConv2d(self.q_logvar_init, self.p_logvar_init, 256, 128, kernel_size=3, padding=1)\n",
    "        self.soft5 = nn.Softplus()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # self.flatten = FlattenLayer(1 * 1 * 128)\n",
    "        # self.fc1 = BBBLinearFactorial(q_logvar_init, N, p_logvar_init, 1* 1 * 128, outputs)\n",
    "\n",
    "\n",
    "        layers = [self.conv1, self.soft1, self.pool1, self.conv2, self.soft2, self.pool2, self.conv3, self.soft3,\n",
    "                  self.conv4, self.soft4, self.conv5, self.soft5, self.pool3]\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def probforward(self, x):\n",
    "        kl = 0\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'convprobforward') and callable(layer.convprobforward):\n",
    "                x, _kl, = layer.convprobforward(x)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x, _kl = self.classifier.fcprobforward(x)\n",
    "        kl += _kl\n",
    "        logits = x\n",
    "        return logits, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if cuda is available\n",
    "if use_cuda:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint path to save\n",
    "ckpt_name = f'model_{net_type}_{dataset}_bayesian.pt'\n",
    "ckpt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(batch_idx, m, beta_type):\n",
    "    if beta_type == \"Blundell\":\n",
    "        beta = 2 ** (m - (batch_idx + 1)) / (2 ** m - 1)\n",
    "    elif beta_type == \"Soenderby\":\n",
    "        beta = min(epoch / (num_epochs // 4), 1)\n",
    "    elif beta_type == \"Standard\":\n",
    "        beta = 1 / m\n",
    "    else:\n",
    "        beta = 0\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo(out, y, kl, beta):\n",
    "    loss = F.cross_entropy(out, y)\n",
    "    return loss + beta * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_beta(epoch_idx, N):\n",
    "    return 1.0 / N / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainity_softmax(output):\n",
    "    prediction = F.softmax(output, dim = 1)\n",
    "    results = torch.max(prediction, 1 )\n",
    "    p_hat = np.array(results[0].cpu().detach())\n",
    "    epistemic = np.mean(p_hat ** 2, axis=0) - np.mean(p_hat, axis=0) ** 2\n",
    "#     epistemic += epistemic \n",
    "    #print (epistemic)\n",
    "    aleatoric = np.mean(p_hat * (1-p_hat), axis = 0)\n",
    "#     aleatoric += aleatoric\n",
    "    #print (aleatoric)\n",
    "    return epistemic, aleatoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty_normalized(output):\n",
    "    outputs = []\n",
    "    for t in range(1):\n",
    "        prediction = F.softplus(output.cpu())\n",
    "        prediction = normalization_function(prediction)\n",
    "        outputs.append(prediction)\n",
    "        \n",
    "    res = np.mean(prediction.numpy(), axis=0)\n",
    "    p_hat= torch.cat(outputs, 1)\n",
    "    p_hat=p_hat.numpy()\n",
    "    T=1\n",
    "    \n",
    "    aleatoric = np.diag(res) - p_hat.T.dot(p_hat)/p_hat.shape[0]\n",
    "#     aleatoric += aleatoric\n",
    "    tmp = p_hat - res  \n",
    "    epistemic = tmp.T.dot(tmp)/tmp.shape[0]\n",
    "#     epistemic += epistemic \n",
    "\n",
    "    print(np.sum(epistemic, keepdims = True))\n",
    "    print(np.sum(aleatoric, keepdims = True))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     p_hat = np.array(res)\n",
    "#     print (p_hat)\n",
    "#     epistemic = np.mean((p_hat) ** 2, axis=0) - np.mean((p_hat), axis=0) ** 2\n",
    "#     epistemic = np.mean((1-p_hat) ** 2, axis=0) - np.mean((1-p_hat), axis=0) ** 2\n",
    "#    epistemic += epistemic \n",
    "#     #print (epistemic)\n",
    "#     aleatoric = np.mean((p_hat) * (1-(p_hat)), axis = 0)\n",
    "#     aleatoric = np.mean((1-p_hat), axis = 0) ** 2\n",
    "#     aleatoric += aleatoric\n",
    "    #print (aleatoric)\n",
    "    return (np.sum(epistemic, keepdims = True)), (np.sum(epistemic, keepdims = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_function(x):\n",
    "    return (x) / torch.sum(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile_train = 'train.csv'\n",
    "fieldnames = ['Epochs', 'Train Accuracy']\n",
    "with open( writefile_train, 'w' ) as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile_test = 'test.csv'\n",
    "fieldnames = ['Epochs', 'Test Accuracy', 'Epistemic Uncertainty', 'Aleatoric Uncertainty']\n",
    "with open( writefile_test, 'w' ) as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('Epoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs, kl = net.probforward(inputs)\n",
    "        loss = elbo(outputs, targets, kl, get_beta(epoch, len(train_data)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = torch.max(outputs, dim=1)[1]\n",
    "        correct += torch.sum(pred.eq(targets)).item()\n",
    "        total += targets.numel()\n",
    "    print(f'[TRAIN] Acc: {100.*correct/total:.3f}')\n",
    "    with open( writefile_train, 'a' ) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([epoch, 100.*correct/total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    accuracy_max = 0    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs, _ = net.probforward(inputs)\n",
    "            epistemic , aleatoric = calc_uncertainty_normalized(outputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            accuracy = 100.*correct/total\n",
    "        print(f'[TEST] Acc: {accuracy:.3f}')\n",
    "        print(f'Epistemic Uncertainty: {epistemic:.6f}')\n",
    "        print(f'Aleatoric Uncertainty: {aleatoric:.6f}\\n')\n",
    "        \n",
    "        with open( writefile_test, 'a' ) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([epoch, 100.*correct/total, epistemic, aleatoric])\n",
    "        \n",
    "\n",
    "    torch.save(net.state_dict(), ckpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [80, 60, 40, 20]\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "for epoch in epochs:\n",
    "    optimizer = Adam(net.parameters(), lr=lr)\n",
    "    for _ in range(epoch):\n",
    "        train(count)\n",
    "        test(count)\n",
    "        count += 1\n",
    "    lr /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "merged=test.merge(train[['Epochs', 'Train Accuracy']], how='left', left_on='Epochs', right_on='Epochs')\n",
    "\n",
    "merged.to_csv('VGG_MNIST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"train.csv\")\n",
    "os.remove(\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
